{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a4878f-081e-403c-b385-f048ecf36866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import leafmap\n",
    "import xarray as xr\n",
    "\n",
    "DATA_DIR = Path(\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbc538-a117-471e-afd0-dc17228f9ac9",
   "metadata": {},
   "source": [
    "#### Download data first\n",
    "\n",
    "We're going to work with some gridded bathymetry data!\n",
    "\n",
    "[direct download](https://dap.ceda.ac.uk/bodc/gebco/global/gebco_2025/ice_surface_elevation/netcdf/gebco_2025.zip?download=1) |\n",
    "[data info](https://www.gebco.net/data-products/gridded-bathymetry-data)\n",
    "\n",
    "Run the cell below to download and extract this data to the `examples/data` directory!\n",
    "\n",
    "⚠️ WARNING: this file extracts to 8gb. It will probably take **at least** 30 minutes to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f93fdc-4c06-4572-86ee-0dd35fe4205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import unquote, urlparse\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_file(url: str, *, dest_dir: Path = Path()) -> Path:\n",
    "    \"\"\"Downloads a file from a URL with a progress bar.\"\"\"\n",
    "    if not dest_dir.is_dir():\n",
    "        raise NotADirectoryError(f\"{dest_dir} must be an existing directory.\")\n",
    "\n",
    "    output_fn = unquote(urlparse(url).path).split(\"/\")[-1]\n",
    "    output_path = dest_dir / output_fn\n",
    "\n",
    "    if output_path.is_file():\n",
    "        print(f\"Already downloaded {output_path}.\")\n",
    "        return output_path\n",
    "\n",
    "    response = requests.get(url, stream=True, timeout=30)\n",
    "\n",
    "    total_size = int(response.headers.get(\"content-length\", 0))\n",
    "    chunk_size = 4096\n",
    "\n",
    "    with (\n",
    "        output_path.open(\"wb\") as f,\n",
    "        tqdm(total=total_size, unit=\"B\", unit_scale=True, desc=output_fn) as progress,\n",
    "    ):\n",
    "        for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                progress.update(len(chunk))\n",
    "    return output_path\n",
    "\n",
    "\n",
    "path = download_file(\n",
    "    \"https://dap.ceda.ac.uk/bodc/gebco/global/gebco_2025/ice_surface_elevation/netcdf/gebco_2025.zip?download=1\",\n",
    "    dest_dir=DATA_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e7684-3b04-4a0d-9c75-47e36b9a0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import unpack_archive\n",
    "\n",
    "# TODO: Skip if already unpacked.\n",
    "# TODO: Save extracted filenames.\n",
    "#       Probably need to write a good amount of code with the zipfiles module?\n",
    "#       ¯\\_(ツ)_/¯\n",
    "unpack_archive(path, extract_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689adc41-ba3a-4875-b10c-482ef3b866de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = DATA_DIR / \"GEBCO_2025.nc\"\n",
    "ds = xr.open_dataset(fp, chunks=\"auto\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5539dae-4698-4e83-9b7b-d4639fbce513",
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = ds[\"elevation\"]\n",
    "elev = elev.rio.write_crs(\"EPSG:4326\")\n",
    "elev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83c4e37-6fa0-44ec-8837-54ee38631313",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a long time, will probably use all your memory.\n",
    "#\n",
    "# elev.plot()  # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd2525d-040a-476c-ad4e-21b0f4531fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_xarray_tiler.titiler import add_data_array\n",
    "\n",
    "url = await add_data_array(elev, colormap_name=\"terrain\", rescale=(-11000, 9000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439499d-11cd-4ac4-ba11-a35caadf5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876d760-76f6-4d24-a3c5-911088d3ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = leafmap.Map()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81293951-57df-4324-a548-006cd3f428b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add_tile_layer(url=url, name=\"World Bathymetry\", attribution=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcfcfba-8cc2-40b7-b8d3-654c46962f2e",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "It's really slow! Especially zoomed out. It seems to use about 8GB of memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
